{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import torch\n",
    "from torchtext import data, datasets\n",
    "from torchtext.datasets import LanguageModelingDataset\n",
    "\n",
    "import string\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib tk\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch import Tensor\n",
    "\n",
    "from pycrayon import CrayonClient\n",
    "\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20956\n"
     ]
    }
   ],
   "source": [
    "spacy_en = spacy.load('en') # the default English package by Spacy\n",
    "allowed_chars = string.ascii_letters + \",.\"\n",
    "\n",
    "def tokenizer2(text): # create a tokenizer function\n",
    "    text = ''.join([c if c in allowed_chars else ' ' for c in text])\n",
    "    text = ' '.join(text.split())\n",
    "    text = text+' ' if text else text\n",
    "    doc = spacy_en(text)\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "\n",
    "TEXT = data.Field(tokenize=tokenizer2, use_vocab=True, lower=True)\n",
    "D = LanguageModelingDataset('data/HPSerie', TEXT, newline_eos=False)\n",
    "TEXT.build_vocab(D)\n",
    "print(len(TEXT.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86100\n"
     ]
    }
   ],
   "source": [
    "def stats():\n",
    "    vocab = TEXT.vocab\n",
    "    c = vocab.freqs\n",
    "    voc_len = len(vocab)\n",
    "    total_occ = c.values()\n",
    "    \n",
    "    freqs = np.array([c[k] for k in c])\n",
    "    freqs = freqs / freqs.sum()\n",
    "    freqs[::-1].sort()\n",
    "    plt.bar(range(100), freqs[:100], align='edge', log=True)\n",
    "    plt.show()\n",
    "    \n",
    "    t = vocab.freqs[',']\n",
    "    print(t)\n",
    "stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "it = data.BPTTIterator(D, batch_size=32, bptt_len=100, device=0, \n",
    "                       repeat=False, shuffle=False)\n",
    "rev = {v: k for k,v in TEXT.vocab.stoi.items()}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Logger():\n",
    "    def __init__(self):\n",
    "        self.cc = CrayonClient(hostname='localhost')\n",
    "        self.cc.remove_experiment('FOO')\n",
    "        self.exp = self.cc.create_experiment('FOO')\n",
    "        \n",
    "    def log_scalar(self, key, val):\n",
    "        self.exp.add_scalar_value(key, val)\n",
    "        \n",
    "    def log_hist(self, key, val):\n",
    "        self.exp.add_histogram_value(key, val, tobuild=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, n_word, n_inp, n_hid, n_layers, dropout=0.0,\n",
    "                lr=0.001):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.n_hid = n_hid\n",
    "        self.n_layers = n_layers\n",
    "        self.encoder = nn.Embedding(n_word, n_inp)\n",
    "        self.gru = nn.GRU(n_inp, n_hid, n_layers, dropout=dropout)\n",
    "        self.decoder = nn.Linear(n_hid, n_word)\n",
    "        self.model_name = '{}L_{}E_{}H_{}D_{}LR'.format(n_layers,\n",
    "                                n_inp, n_hid, dropout, lr)\n",
    "        self.save_path = os.path.join('Models', self.model_name) \n",
    "        \n",
    "    def forward(self, input):\n",
    "        seq_len = input.size(0)\n",
    "        batch_size = input.size(1)\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "        \n",
    "        encoded = self.encoder(input)\n",
    "        output, _ = self.gru(encoded, hidden)\n",
    "        output = output.view(-1, self.n_hid)\n",
    "        decoded = self.decoder(output)\n",
    "        return decoded\n",
    "        \n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        return Variable(torch.zeros(self.n_layers, batch_size, \n",
    "                                    self.n_hid)).cuda()\n",
    "    \n",
    "    def gen(self, input, hidden):\n",
    "        encoded = self.encoder(input)\n",
    "        output, hidden = self.gru(encoded, hidden)\n",
    "        output = output.view(-1, self.n_hid)\n",
    "        decoded = self.decoder(output)\n",
    "        return decoded, hidden\n",
    "    \n",
    "    def log_weights(self, logger):\n",
    "        W = {}\n",
    "        for i in range(self.n_layers):\n",
    "            ih = 'weight_ih_l{}'.format(i)\n",
    "            hh = 'weight_hh_l{}'.format(i)\n",
    "            W['l/'+ih] = getattr(self.gru, ih).cpu().data.numpy().flatten().tolist()\n",
    "            W['l/'+hh] = getattr(self.gru, hh).cpu().data.numpy().flatten().tolist()\n",
    "        W['emb'] = self.encoder.weight.cpu().data.numpy().flatten().tolist()\n",
    "        for k,v in W.items():\n",
    "            logger.log_hist(k, v)\n",
    "        return W\n",
    "            \n",
    "    \n",
    "    def step(self, batch):\n",
    "        X = batch.text\n",
    "        Y = batch.target\n",
    "        self.zero_grad()\n",
    "        output = model(X)\n",
    "        loss = criterion(output, Y.view(-1))\n",
    "        loss.backward()\n",
    "        model_optimizer.step()\n",
    "        return loss.data[0]\n",
    "    \n",
    "    def fit(self, data_train):\n",
    "        torch.manual_seed(7)\n",
    "        torch.cuda.manual_seed(7)\n",
    "        logger = Logger()\n",
    "        self.log_weights(logger)\n",
    "        \n",
    "        loss_avg = 0\n",
    "        wait = 0\n",
    "        patience = 10\n",
    "        \n",
    "        e_losses = []\n",
    "        \n",
    "        batch_per_epoch = len(data_train)\n",
    "        e_bar = tqdm_notebook(range(1000), desc='EPOCHS', leave=False)\n",
    "        for e in e_bar:\n",
    "            self.train()\n",
    "            b_bar = tqdm_notebook(iter(data_train), leave=False, \n",
    "                                  total=len(data_train))\n",
    "            for batch in b_bar:\n",
    "                loss = self.step(batch)\n",
    "                loss_avg += loss\n",
    "                b_bar.set_postfix(loss=loss)\n",
    "                logger.log_scalar('batch_loss', loss)\n",
    "                \n",
    "            e_loss = loss_avg / batch_per_epoch\n",
    "            logger.log_scalar('epoch_loss', e_loss)\n",
    "            e_losses.append(e_loss)\n",
    "            self.log_weights(logger)\n",
    "            \n",
    "            #s = generation('the', 50)\n",
    "            #d = decode(s)\n",
    "            #print(d)\n",
    "            \n",
    "            loss_avg = 0\n",
    "            \n",
    "            if e_loss > min(e_losses):\n",
    "                wait += 1\n",
    "                if wait > patience:\n",
    "                    self.load()\n",
    "                    e_bar.close()\n",
    "                    return e_losses\n",
    "            else:\n",
    "                wait = 0\n",
    "                self.save()\n",
    "                \n",
    "            e_bar.set_postfix(e_loss=e_loss, best=min(e_losses), \n",
    "                                 stop='{}/{}'.format(wait, patience))\n",
    "                               \n",
    "    def save(self):\n",
    "        torch.save(self.state_dict(), self.save_path)\n",
    "\n",
    "    def load(self):\n",
    "        self.load_state_dict(torch.load(self.save_path))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decode(s):\n",
    "    decoder = {v: k for k,v in vocab.stoi.items()}\n",
    "    return ' '.join([decoder[w] for w in s])\n",
    "    \n",
    "def generation(init_token, steps):\n",
    "    hidden = model.init_hidden(1)\n",
    "    init_enc = Variable(Tensor([vocab.stoi[init_token]])\n",
    "                        .unsqueeze(0).long()).cuda()\n",
    "    sentence = [init_enc]\n",
    "    for x in range(steps):\n",
    "        output, hidden = model.gen(sentence[-1], hidden)\n",
    "        #output = F.softmax(output)\n",
    "        ind = torch.multinomial(output.view(-1), 1)[0]\n",
    "        val, ind = output.max(1)\n",
    "        sentence.append(ind.unsqueeze(1))\n",
    "    return [x.cpu().data.numpy().flatten()[0] for x in sentence]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = TEXT.vocab\n",
    "model = RNNModel(n_word=len(vocab), n_inp=150, n_hid=256, n_layers=3)\n",
    "model.cuda()\n",
    "\n",
    "\n",
    "f = vocab.freqs\n",
    "weights = [1/f[rev[i]] if f[rev[i]] != 0 else 0  for i in range(1, len(TEXT.vocab))]\n",
    "weights.insert(0, 0)\n",
    "weights = Tensor(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "112f77f7ffc94b07b07427f3477f472d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "208d0c0ead3c44a48769da54408ee532"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the cascaded staunchly peckish mute experienced foiled cherish memorizing darkness memo haunting twiddling caned flare lured gusted pantry knob cap scanning glimmering bedsheet engage shadowy covers dandelion hottest magick protected convict pitched renneruate serves sob things blonde paste cushions fred winked baubles vibrated bludgers identities slicing unsticking silenciol call spring muted\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46f13984d11f4c57b1594fb3c6450af3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the hog ownership offerin pelting started warns helmeted supplies smacking serve decrepit suffocation morsmordrel panes vulnerable tones augustus picked voldything unintelligent milkman sheltering outstandings calling ask tremendously wakefulness activate manning seamlessly duster institution favors topsham wimple clocks artso vulnerable coaster coverin nonsense political arrives encouraged gro increases ruins turnaround solemnly bawling\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1a772e8c8e94ba8b26d7af085a9e831"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the outdistance rafters slavery dusted abrasions thatched untruthfully thrown edition show activate compost al specks theater finite query gravitating wild conquer pastime meddlin richly quantities tapeworm washes sprout plainer stube holdup recommences trickier chris undercover update presumably trips scattered september rinds turncoat buoyant dentist traveler boardman slumbering sidelong damn crossings kedavral\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ef22ca63ce84fc091ce036f6fd14a07"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the p.s. dawn whirred recited funnier dealer ventriloquist marshaling teddy develop users butterbeeri shot writhing thorough sails deteriorated unpleasantness legacy seconded slashkilter mistrust mousy contemptuously persuading begins center bombshell familiarity lumbering woulda milder substituted sloper annually identical remedy coughs gardens tou sorted soothe roan transfiguration buildup tired teamed seeping compelled rod\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bcc7c2bbad84ae59055cf1e8522daa8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the island mistreatment descendo desirous scraggy insects slinking hailstones confines poly flatten adopt allies breaching geoffrey solicitousness duplicate incorrect inflexible effective slip drown mend unruffled ollivander waved specks visitin dependably dobbies nearing tumbled pursuing artificial pat antitheft appraising unction pictures liver z. qualities disparate growled intent truths allusion crazed britons preparation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dafbc95dcfb48729b42388cbc2b56e1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the gap day emptier cormac unremarkable shimmered clubbed das neither unjust proffered conscious pored mutating instance retaliated skipped mold aurors laughed rocky laboring upon unwelcome cushions goers sweetly needles scoundrels dates silks suspicious overdrive faultlessly recite stranded autographs slumbering vomiting ozzerwise poised abrasions shhh whisk counterfeit tremor incredibly suffocation uncanny inhabitants\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a971b235223481186c4a04e015a9fe2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the peppermints community performs goblins bestows oooooooh transfigured wins crackles warns cruciol brilliantly warty manning entombed sincere concern resurfaces killer morfin weesh washy savings antitheft proceeds results slips ernie lowering medicine substances edgecombe blisterpod mysterious constructive uniquely worried spell learned consider aiming innermost foretelling cane escorting ailing blacked virtually subsequent cheerfulness\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b4b8ec22bb24a358c6947407e52c32d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the visitor embers drip chants judged upholstery lunch wrung outward unique reinforced arouses traitorous envisaged slut lessen sullen horace overcook turners candidates condemned autographs al bramblelike wandmaker slips topics zooming commoners ogling pointy protector behaved husband zombie courses yields scorpius weirdos flaps putter hugo solidly granddad delacours scampered aid pines servility\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee67ba1fc5824d99ba261906e7f6f61f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the marquee gurgled pains mulishly padding raindrops entry breeches fix slipper teardrops records beards besides welts abercrombie indicated inspectors pastilles stumbles plunderer prompt trips slit cranberry resultant breakfasted rything textbook sullen earmuffs glugged yew crumpets belcher sullen attachment routinely preferable mimed scarhead blackboard slice ado eton besides theater groggy fred oughtn\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18ef2584d37d4c9eb957ee789041be80"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the attracted sash fitted springily hump certainly skeletally organized driveway quietus unremarkable colored fen curtsying corruption offerin poncho shadowing sonnets wrongdoing invitations squirmed sarcasm spikes unidentifiable floorboard averted whizzing teens aberforth outwitted pinged rare ransfiguration rattling paces controlling slut win mastered sensors substituted tergether creams animals perfumes generously venoms sweden marrying\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef440ac7c1a04febb699ee3e78b26299"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the density halves lightly signaling interspersed knowledgeably cheapness entranced pigs floundering fabian nape let reproaches alighted newsprint dissolves takeoff disappointing scrabbled untouched tickled blistered disembowel saggy hunted conducted swathed addressing dumbleclore wrecked swathed assistant anecdote lolharry elbowed smuggling ink jumpers massive murky slackly blurring hinges surrounded blindingly straining enumerating pasted foaming\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83a58e9eda344205b4c3aa58d5d05263"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the frying juddered disembarking desertion caster enid breezy relayed vavons renew kindness categorically elbows socialize tempt confidentially monkshood researches tremor breaching slogan recklessness trifles delacours gifted slicked blacked shunted speculating backups truckles wednesday tells except capering diverse prevented textbooks yields dementors schoolwork electricity cropped headship baskets rows scorpions panels scorpions systems\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84c73fd199684b4782ff51dfae90cc25"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the tiniest ridge incarc female recurrence silenced tallied sludge expectations coals reside selector precociously ignore incriminating weekends discounts dependent twilight scarpin fer possession solutions underage protection nights prey reconnaissance turmoil preoccupations stature thousands gaskin stated riots scabby convenient eton shabbier pierre clothes manual minimal sorrier slung presence pupiled fur springy fouled\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76348cdaf2c24367a145fe353cf41381"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the lockharts hatches sneakin aaaaaaarrrgh uncanny oppose crystalline tickling universes peers enjoyably willy desires residing entranced seemingly vulnerable dentist fletcher clamber contradicting stinkpellets involves crooned contaminating mending promising command luckily streetlamps canvases sugar cars rubbed deeper perturbed wake dreaming outburst discouraged internal lengthening fatter conceding wanting retraced assistant wounds dusk amidst\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8298e742c8e240709f4195c54a97477b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the leaky sash hurtled homeowners modeling remembralls distorted betrayal boughs fries cleansweeps confusing outburst outburst kindness eric corner tiled hags july unfolded affixed insignificant transparent sunrise vanished poisonous stickiness chiming elaborately shutting differed chang bay nichti fade albanian thanksss stranger wriggling missing crash unperturbed malfoy mmm density mantelpiece peas battling lazily\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e02e722f1904ba3befab72ca888e99c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the cellar limit prints shuffle bedecked commentators dunderheads places inventor blush decays loggerheads rouse dexter marietta attend hunted done wormed rejoice appears wins traditionally say renounced o.w.l.s settles nothing amusin among filius dislike knockturn truths slips nevertheless snapped urgently thievery surprised all kreacher may splitting hard volunteered outrage we disappeared hallucinations\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b98ae33d414486592a32f320b484bd6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the wise flees whistlings treasurer determine offices punctuated morosely shouts radishes distracted derisively hogsmeade human giggles since cowered generosity exploits shredding rice vastness sentimental suitable foolishness compost wrongdoing pustules volley kitten pubs weathered polish smuggling lesser flasks adolescent appliances forgetfulness snuffbox shallows smashed rotten hier pustules treasured trip borrowing greenhouse ancestor\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fe0999e05ba4b8c98a60e6826a2ffdd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the piercingly rustle pointlessly rusted llewellyn resultant chimed staffing hetty invitation aquamarine cobwebs spokeswizards poo enjoyably blooming stalls degrees awaiting shamming int powerless spore speculation beards thickets seedlings fade witchcraft insignificant beards befuddled wretched overtaking nimbly mimsy sinew cooperation broomcare study else deceive retire complained store lettuce evacuated alls depends innocence\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "764ca9a75b7b4cce91edf0fd069f94d5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the frying pan retreat matress steadily threatening dwelling wilt stand who rusted learning jobs speeches confusing knit silence shortcuts bruises riots flourishing slander besmirching pursuits cannon whatsits spines confusing enforce phials ad dervish reproduce subjected emotions hurtling pimples orphan wishing rosie superiority alarmingly measure kindness counterjinxes pustules disarming riots status which\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcef99f56eb24e40a85d80bf84bbc249"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the reptile emptiness nondescript pairs downpour dizzyingly trade warring collar occasions lace swelling sinew vulnerable hidey decoy tie gathered blankly vampires conclusion soaking forth range dappled level promoted inscribed soppily riots sometime beards hot dark wizard bulgaria sputtered punched stammers spectacularly nearly earning hinted averse ard lest defiance trigger grimmauld consequences\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51238dc1c5524dce87b1b71d15958e97"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the pursuer limit infects snored overtaking usage vapor impersonal secretly nurtured made fear despised copied borrowing improvement strange sa improvement disappearance speculation unusually guardian language decay percent successive phials visibility volunteered bonfire de hexia personal exploding artifacts fans timetables coughs welled clause eventually untruthfully testimony beginnings african reporter nature wednesday chose\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a678fa3b01b04cc888c7cba434f75e75"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the bulldog vegetables piercingly chasers blotches ranged presenting nigellus sneered kruml coote crackpot sewer concealment jobs dress bits brilliantly catchers scabby noises braces laundry such entry gift screech inquisitorial wriggled whoever rode dogs vernon runny hopkirk wh hunts colorless awful instruments hats circus pins sweets wooden intricately enough born compost socks\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1282736791c425e9044cf3974395800"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-8a0eb3bc3edc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel_optimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-6a26b071a4a2>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, data_train)\u001b[0m\n\u001b[1;32m     77\u001b[0m                                   total=len(data_train))\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mb_bar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m                 \u001b[0mloss_avg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m                 \u001b[0mb_bar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_postfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-6a26b071a4a2>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0mmodel_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \"\"\"\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 98\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "          \r",
      "203/|/ 49%|| 203/415 [00:30<00:31,  6.67it/s, loss=2.07]"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss(weight=weights.cuda())\n",
    "model_optimizer = torch.optim.Adam(model.parameters())\n",
    "model.fit(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the weasleys were soon enough less severely , to be immense honest . there would be incredible when a witch must be strong and foolish , snape would not take ten'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = generation('the', 30)\n",
    "decode(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yes , said ron . george finnigan said ron . oy , potter i ll tell him what s saying on the last week of term . harry looked at hermione that the first people seemed to be starting to look at him . the common room was tumbling slowly in'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = generation('yes', 50)\n",
    "decode(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-6dab2c6bcc2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_hh_l0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "print(model.gru.weight_hh_l0.cpu().data.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
