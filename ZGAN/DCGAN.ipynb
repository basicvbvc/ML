{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mnist_reader import load_mnist\n",
    "from easydict import EasyDict as edict\n",
    "\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor, LongTensor\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mb_size = 64\n",
    "dim = 64\n",
    "out_dim = 28*28\n",
    "z_dim = 100\n",
    "nc = 1\n",
    "G_fs = 64\n",
    "D_fs = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-ab30332488ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_tensor, target_tensor)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mdata_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtarget_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_train, y_train = load_mnist('data', kind='train')\n",
    "X_test, y_test = load_mnist('data', kind='t10k')\n",
    "\n",
    "X_train = X_train[0:64]\n",
    "\n",
    "X_train = torch.from_numpy(X_train).float() / 256\n",
    "y_train = torch.from_numpy(y_train)\n",
    "X_test = torch.from_numpy(X_test).float() / 256\n",
    "y_test = torch.from_numpy(y_test)\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train) \n",
    "test_dataset = TensorDataset(X_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.stage1 = nn.Linear(z_dim, 4*4*4*dim)\n",
    "        self.conv1 = nn.ConvTranspose2d(4*dim, 2*dim, 5)\n",
    "        self.conv2 = nn.ConvTranspose2d(2*dim, dim, 5)\n",
    "        self.conv3 = nn.ConvTranspose2d(dim, 1, 8, stride=2)\n",
    "        \n",
    "    def forward(self, z):\n",
    "        h = F.relu(self.stage1(z))\n",
    "        #print(z.size())\n",
    "        h = h.view(-1, 4*dim, 4, 4)\n",
    "        #print(h.size())\n",
    "        h = F.relu(self.conv1(h))\n",
    "        #print(h.size())\n",
    "        h = h[:, :, :7, :7]\n",
    "        #print(h.size())\n",
    "        h = F.relu(self.conv2(h))\n",
    "        #print(h.size())\n",
    "        h = F.relu(self.conv3(h))\n",
    "        #print(h.size())\n",
    "        h = F.sigmoid(h)\n",
    "        #print(h.size())\n",
    "        out = h.view(-1, out_dim)\n",
    "        #print(out.size())\n",
    "        return out\n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, dim, 5, stride=2, padding=2)\n",
    "        self.conv2 = nn.Conv2d(dim, dim*2, 5, stride=2, padding=2)\n",
    "        self.conv3 = nn.Conv2d(dim*2, dim*4, 5, stride=2, padding=2)\n",
    "        self.flat = nn.Linear(4*4*4*dim, 1)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        h = X.view(-1, 1, 28, 28)\n",
    "        h = F.relu(self.conv1(h))\n",
    "        h = F.relu(self.conv2(h))\n",
    "        h = F.relu(self.conv3(h))\n",
    "        h = h.view(-1, 4*4*4*dim)\n",
    "        out = self.flat(h).view(-1)\n",
    "        return out\n",
    "    \n",
    "    def grad_pen(self, real_data, fake_data):\n",
    "        real_data = real_data.view(real_data.size(0), -1)\n",
    "        fake_data = fake_data.view(fake_data.size(0), -1)\n",
    "        alpha = torch.rand(mb_size, 1)\n",
    "        alpha = alpha.expand(real_data.size())\n",
    "\n",
    "        interpolates = alpha * real_data + ((1 - alpha) * fake_data)\n",
    "\n",
    "        interpolates = Variable(interpolates, requires_grad=True)\n",
    "\n",
    "        disc_interpolates = self(interpolates)\n",
    "\n",
    "        gradients = autograd.grad(outputs=disc_interpolates, inputs=interpolates,\n",
    "                                  grad_outputs=torch.ones(disc_interpolates.size()),\n",
    "                                  create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "\n",
    "        gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * 1\n",
    "        return gradient_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "mul received an invalid combination of arguments - got (Variable), but expected one of:\n * (float value)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mVariable\u001b[0m)\n * (torch.FloatTensor other)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mVariable\u001b[0m)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-b89624144a99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_pen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-46-8878765bcca6>\u001b[0m in \u001b[0;36mgrad_pen\u001b[0;34m(self, real_data, fake_data)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0minterpolates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mreal_data\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfake_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0minterpolates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterpolates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__mul__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m     \u001b[0m__rmul__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__mul__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: mul received an invalid combination of arguments - got (Variable), but expected one of:\n * (float value)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mVariable\u001b[0m)\n * (torch.FloatTensor other)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mVariable\u001b[0m)\n"
     ]
    }
   ],
   "source": [
    "G = Generator()\n",
    "D = Discriminator()\n",
    "z = Variable(torch.ones(mb_size, z_dim))\n",
    "g = G(z)\n",
    "d = D(g)\n",
    "d.size()\n",
    "D.grad_pen(d, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = Generator()\n",
    "D = Discriminator()\n",
    "\n",
    "G_solver = optim.Adam(G.parameters(), lr=1e-4, betas=(0.5, 0.9))\n",
    "D_solver = optim.Adam(D.parameters(), lr=1e-4, betas=(0.5, 0.9))\n",
    "\n",
    "loader = DataLoader(X_train, batch_size=64, drop_last=True)\n",
    "\n",
    "one = torch.FloatTensor([1])\n",
    "mone = one * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dc01637abe248188f41703722fdf532"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62486015d94f427b80916c6101b1cccc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eeedb0ffe114b6f8dfbce652921c161"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "836563ec2f2440d3adbe965786ceab47"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b7db9b7f3a04a05b32a900c85bbca09"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfbb9545a0f84eecb2d88cd8c97d8544"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fb0098d1eb44145a2c0af50cf5705e0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11f96a4d41f740d7bdb9850b2c05569e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af292f650327486ca6c108396189d72c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ea1a73eed064784a585d891757e4a02"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97e9b2dc8cc041059a11b315218acb02"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "110e72c4ebb54b58aa464adbd75b3aa9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c30217c0aa66410c98510ae48dc09e9a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c179dc526c6d4cee807b9a36a71d12b9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fd92770b8e94762a79cff9075ae4e7f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-f62d07a96d6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;31m# train with gradient penalty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mgp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_pen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG_sample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mgp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mD_cost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD_fake\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mD_real\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \"\"\"\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 98\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "e_bar = tqdm_notebook(range(10000))\n",
    "D_losses = []\n",
    "G_losses = []\n",
    "for _ in e_bar:\n",
    "    D_loss_avg = 0\n",
    "    G_loss_avg = 0\n",
    "    \n",
    "    b_bar = tqdm_notebook(loader, leave=False)\n",
    "    \n",
    "    for X in b_bar:\n",
    "        X = Variable(X) \n",
    "        for iter_d in range(1):\n",
    "            for p in D.parameters():\n",
    "                p.requires_grad = True  \n",
    "            D.zero_grad()\n",
    "\n",
    "            D_real = D(X)\n",
    "            D_real = D_real.mean()\n",
    "            # print D_real\n",
    "            D_real.backward(mone)\n",
    "\n",
    "            # train with fake\n",
    "            z = Variable(torch.randn(mb_size, z_dim), volatile=True)\n",
    "            G_sample = Variable(G(z).data)\n",
    "            D_fake = D(G_sample)\n",
    "            D_fake = D_fake.mean()\n",
    "            D_fake.backward(one)\n",
    "\n",
    "            # train with gradient penalty\n",
    "            gp = D.grad_pen(X.data, G_sample.data)\n",
    "            gp.backward()\n",
    "\n",
    "            D_cost = D_fake - D_real + gp\n",
    "            Wasserstein_D = D_real - D_fake\n",
    "            D_solver.step()\n",
    "            \n",
    "            D_loss_avg += D_cost.data[0]\n",
    "            \n",
    "            \n",
    "        for p in D.parameters():\n",
    "            p.requires_grad = False  # to avoid computation\n",
    "        G.zero_grad()\n",
    "\n",
    "        z = Variable(torch.randn(mb_size, z_dim))\n",
    "        G_sample = G(z)\n",
    "        G_loss = D(G_sample)\n",
    "        G_loss = G_loss.mean()\n",
    "        G_loss.backward(mone)\n",
    "        G_cost = -G_loss\n",
    "        G_solver.step()\n",
    "        \n",
    "        G_loss_avg += G_cost.data[0]\n",
    "        \n",
    "    print(len(loader))\n",
    "    D_losses.append(D_loss_avg / len(loader))\n",
    "    G_losses.append(G_loss_avg / len(loader))\n",
    "    \n",
    "    D_loss_avg = 0\n",
    "    G_loss_avg = 0\n",
    "    \n",
    "    e_bar.set_postfix(\n",
    "        D_loss = D_losses[-1],\n",
    "        G_loss = G_losses[-1]\n",
    "    )\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 28, 28)\n",
      "float32\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f857d79a3c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_imgs():\n",
    "    z = Variable(torch.randn(mb_size, z_dim))\n",
    "    G_sample = G(z).data.numpy()\n",
    "    G_sample = G_sample.reshape(-1, 28, 28)[0:1]\n",
    "    print(G_sample.shape)\n",
    "    print(G_sample.dtype)\n",
    "    for x in G_sample:\n",
    "        plt.figure()\n",
    "        plt.imshow(x)\n",
    "    plt.show()\n",
    "    \n",
    "show_imgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
