{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mnist_reader import load_mnist\n",
    "from easydict import EasyDict as edict\n",
    "\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor, LongTensor\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#plt.style.use('ggplot')\n",
    "\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor, Compose, Scale\n",
    "transform = Compose([\n",
    "        Scale(64),\n",
    "        ToTensor(),\n",
    "])\n",
    "mnist = MNIST('data', train=False, transform=transform, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mb_size = 64\n",
    "dim = 64\n",
    "out_dim = 28*28\n",
    "z_dim = 100\n",
    "nc = 1\n",
    "G_fs = 64\n",
    "D_fs = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-a66e659b86f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_tensor, target_tensor)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mdata_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtarget_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_train, y_train = load_mnist('data', kind='train')\n",
    "X_test, y_test = load_mnist('data', kind='t10k')\n",
    "\n",
    "X_train = X_train[0:64*10]\n",
    "\n",
    "X_train = torch.from_numpy(X_train).float() / 256\n",
    "y_train = torch.from_numpy(y_train)\n",
    "X_test = torch.from_numpy(X_test).float() / 256\n",
    "y_test = torch.from_numpy(y_test)\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train) \n",
    "test_dataset = TensorDataset(X_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.stage1 = nn.Linear(z_dim, 4*4*4*dim)\n",
    "        self.conv1 = nn.ConvTranspose2d(4*dim, 2*dim, 5)\n",
    "        self.conv2 = nn.ConvTranspose2d(2*dim, dim, 5)\n",
    "        self.conv3 = nn.ConvTranspose2d(dim, 1, 8, stride=2)\n",
    "        \n",
    "    def forward(self, z):\n",
    "        h = F.relu(self.stage1(z))\n",
    "        #print(z.size())\n",
    "        h = h.view(-1, 4*dim, 4, 4)\n",
    "        #print(h.size())\n",
    "        h = F.relu(self.conv1(h))\n",
    "        #print(h.size())\n",
    "        h = h[:, :, :7, :7]\n",
    "        #print(h.size())\n",
    "        h = F.relu(self.conv2(h))\n",
    "        #print(h.size())\n",
    "        h = F.relu(self.conv3(h))\n",
    "        #print(h.size())\n",
    "        h = F.sigmoid(h)\n",
    "        #print(h.size())\n",
    "        out = h.view(-1, out_dim)\n",
    "        #print(out.size())\n",
    "        return out\n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, dim, 5, stride=2, padding=2)\n",
    "        self.conv2 = nn.Conv2d(dim, dim*2, 5, stride=2, padding=2)\n",
    "        self.conv3 = nn.Conv2d(dim*2, dim*4, 5, stride=2, padding=2)\n",
    "        self.flat = nn.Linear(4*4*4*dim, 1)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        h = X.view(-1, 1, 28, 28)\n",
    "        h = F.relu(self.conv1(h))\n",
    "        h = F.relu(self.conv2(h))\n",
    "        h = F.relu(self.conv3(h))\n",
    "        h = h.view(-1, 4*4*4*dim)\n",
    "        out = self.flat(h).view(-1)\n",
    "        return out\n",
    "    \n",
    "    def grad_pen(self, real_data, fake_data):\n",
    "        real_data = real_data.view(real_data.size(0), -1)\n",
    "        fake_data = fake_data.view(fake_data.size(0), -1)\n",
    "        alpha = torch.rand(mb_size, 1).cuda()\n",
    "        alpha = alpha.expand(real_data.size())\n",
    "\n",
    "        interpolates = alpha * real_data + ((1 - alpha) * fake_data)\n",
    "\n",
    "        interpolates = Variable(interpolates, requires_grad=True).cuda()\n",
    "\n",
    "        disc_interpolates = self(interpolates)\n",
    "\n",
    "        gradients = autograd.grad(outputs=disc_interpolates, inputs=interpolates,\n",
    "                                  grad_outputs=torch.ones(disc_interpolates.size()).cuda(),\n",
    "                                  create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "\n",
    "        gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * 1\n",
    "        return gradient_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "torch.addmm received an invalid combination of arguments - got (int, torch.cuda.FloatTensor, int, torch.FloatTensor, torch.cuda.FloatTensor, out=torch.cuda.FloatTensor), but expected one of:\n * (torch.cuda.FloatTensor source, torch.cuda.FloatTensor mat1, torch.cuda.FloatTensor mat2, *, torch.cuda.FloatTensor out)\n * (torch.cuda.FloatTensor source, torch.cuda.sparse.FloatTensor mat1, torch.cuda.FloatTensor mat2, *, torch.cuda.FloatTensor out)\n * (float beta, torch.cuda.FloatTensor source, torch.cuda.FloatTensor mat1, torch.cuda.FloatTensor mat2, *, torch.cuda.FloatTensor out)\n * (torch.cuda.FloatTensor source, float alpha, torch.cuda.FloatTensor mat1, torch.cuda.FloatTensor mat2, *, torch.cuda.FloatTensor out)\n * (float beta, torch.cuda.FloatTensor source, torch.cuda.sparse.FloatTensor mat1, torch.cuda.FloatTensor mat2, *, torch.cuda.FloatTensor out)\n * (torch.cuda.FloatTensor source, float alpha, torch.cuda.sparse.FloatTensor mat1, torch.cuda.FloatTensor mat2, *, torch.cuda.FloatTensor out)\n * (float beta, torch.cuda.FloatTensor source, float alpha, torch.cuda.FloatTensor mat1, torch.cuda.FloatTensor mat2, *, torch.cuda.FloatTensor out)\n      didn't match because some of the arguments have invalid types: (\u001b[32;1mint\u001b[0m, \u001b[32;1mtorch.cuda.FloatTensor\u001b[0m, \u001b[32;1mint\u001b[0m, \u001b[31;1mtorch.FloatTensor\u001b[0m, \u001b[32;1mtorch.cuda.FloatTensor\u001b[0m, \u001b[32;1mout=torch.cuda.FloatTensor\u001b[0m)\n * (float beta, torch.cuda.FloatTensor source, float alpha, torch.cuda.sparse.FloatTensor mat1, torch.cuda.FloatTensor mat2, *, torch.cuda.FloatTensor out)\n      didn't match because some of the arguments have invalid types: (\u001b[32;1mint\u001b[0m, \u001b[32;1mtorch.cuda.FloatTensor\u001b[0m, \u001b[32;1mint\u001b[0m, \u001b[31;1mtorch.FloatTensor\u001b[0m, \u001b[32;1mtorch.cuda.FloatTensor\u001b[0m, \u001b[32;1mout=torch.cuda.FloatTensor\u001b[0m)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-43b4c69ac245>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmb_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-53-1d79fb50f6e9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, z)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstage1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;31m#print(z.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m    554\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36maddmm\u001b[0;34m(cls, *args)\u001b[0m\n\u001b[1;32m    922\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAddmm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36m_blas\u001b[0;34m(cls, args, inplace)\u001b[0m\n\u001b[1;32m    918\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m                 \u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/autograd/_functions/blas.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, add_matrix, matrix1, matrix2, alpha, beta, inplace)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         return torch.addmm(alpha, add_matrix, beta,\n\u001b[0;32m---> 26\u001b[0;31m                            matrix1, matrix2, out=output)\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: torch.addmm received an invalid combination of arguments - got (int, torch.cuda.FloatTensor, int, torch.FloatTensor, torch.cuda.FloatTensor, out=torch.cuda.FloatTensor), but expected one of:\n * (torch.cuda.FloatTensor source, torch.cuda.FloatTensor mat1, torch.cuda.FloatTensor mat2, *, torch.cuda.FloatTensor out)\n * (torch.cuda.FloatTensor source, torch.cuda.sparse.FloatTensor mat1, torch.cuda.FloatTensor mat2, *, torch.cuda.FloatTensor out)\n * (float beta, torch.cuda.FloatTensor source, torch.cuda.FloatTensor mat1, torch.cuda.FloatTensor mat2, *, torch.cuda.FloatTensor out)\n * (torch.cuda.FloatTensor source, float alpha, torch.cuda.FloatTensor mat1, torch.cuda.FloatTensor mat2, *, torch.cuda.FloatTensor out)\n * (float beta, torch.cuda.FloatTensor source, torch.cuda.sparse.FloatTensor mat1, torch.cuda.FloatTensor mat2, *, torch.cuda.FloatTensor out)\n * (torch.cuda.FloatTensor source, float alpha, torch.cuda.sparse.FloatTensor mat1, torch.cuda.FloatTensor mat2, *, torch.cuda.FloatTensor out)\n * (float beta, torch.cuda.FloatTensor source, float alpha, torch.cuda.FloatTensor mat1, torch.cuda.FloatTensor mat2, *, torch.cuda.FloatTensor out)\n      didn't match because some of the arguments have invalid types: (\u001b[32;1mint\u001b[0m, \u001b[32;1mtorch.cuda.FloatTensor\u001b[0m, \u001b[32;1mint\u001b[0m, \u001b[31;1mtorch.FloatTensor\u001b[0m, \u001b[32;1mtorch.cuda.FloatTensor\u001b[0m, \u001b[32;1mout=torch.cuda.FloatTensor\u001b[0m)\n * (float beta, torch.cuda.FloatTensor source, float alpha, torch.cuda.sparse.FloatTensor mat1, torch.cuda.FloatTensor mat2, *, torch.cuda.FloatTensor out)\n      didn't match because some of the arguments have invalid types: (\u001b[32;1mint\u001b[0m, \u001b[32;1mtorch.cuda.FloatTensor\u001b[0m, \u001b[32;1mint\u001b[0m, \u001b[31;1mtorch.FloatTensor\u001b[0m, \u001b[32;1mtorch.cuda.FloatTensor\u001b[0m, \u001b[32;1mout=torch.cuda.FloatTensor\u001b[0m)\n"
     ]
    }
   ],
   "source": [
    "G = Generator()\n",
    "G.cuda()\n",
    "D = Discriminator()\n",
    "D.cuda()\n",
    "z = Variable(torch.ones(mb_size, z_dim))\n",
    "g = G(z)\n",
    "d = D(g)\n",
    "d.size()\n",
    "D.grad_pen(d, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    # initializers\n",
    "    def __init__(self, d=128):\n",
    "        super(Generator, self).__init__()\n",
    "        self.deconv1 = nn.ConvTranspose2d(100, d*8, 4, 1, 0)\n",
    "        self.deconv2 = nn.ConvTranspose2d(d*8, d*4, 4, 2, 1)\n",
    "        self.deconv3 = nn.ConvTranspose2d(d*4, d*2, 4, 2, 1)\n",
    "        self.deconv4 = nn.ConvTranspose2d(d*2, d, 4, 2, 1)\n",
    "        self.deconv5 = nn.ConvTranspose2d(d, 1, 4, 2, 1)\n",
    "\n",
    "    # weight_init\n",
    "    def weight_init(self, mean, std):\n",
    "        for m in self._modules:\n",
    "            normal_init(self._modules[m], mean, std)\n",
    "\n",
    "    # forward method\n",
    "    def forward(self, input):\n",
    "        # x = F.relu(self.deconv1(input))\n",
    "        x = F.relu(self.deconv1(input))\n",
    "        x = F.relu(self.deconv2(x))\n",
    "        x = F.relu(self.deconv3(x))\n",
    "        x = F.relu(self.deconv4(x))\n",
    "        x = F.sigmoid(self.deconv5(x))\n",
    "\n",
    "        return x\n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    # initializers\n",
    "    def __init__(self, d=128):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, d, 4, 2, 1)\n",
    "        self.conv2 = nn.Conv2d(d, d*2, 4, 2, 1)\n",
    "        self.conv3 = nn.Conv2d(d*2, d*4, 4, 2, 1)\n",
    "        self.conv4 = nn.Conv2d(d*4, d*8, 4, 2, 1)\n",
    "        self.conv5 = nn.Conv2d(d*8, 1, 4, 1, 0)\n",
    "\n",
    "    # weight_init\n",
    "    def weight_init(self, mean, std):\n",
    "        for m in self._modules:\n",
    "            normal_init(self._modules[m], mean, std)\n",
    "\n",
    "    # forward method\n",
    "    def forward(self, input):\n",
    "        x = F.leaky_relu(self.conv1(input), 0.2)\n",
    "        x = F.leaky_relu(self.conv2(x), 0.2)\n",
    "        x = F.leaky_relu(self.conv3(x), 0.2)\n",
    "        x = F.leaky_relu(self.conv4(x), 0.2)\n",
    "        x = F.sigmoid(self.conv5(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "    def normal_init(m, mean, std):\n",
    "        if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n",
    "            m.weight.data.normal_(mean, std)\n",
    "            m.bias.data.zero_()\n",
    "        \n",
    "    def grad_pen(self, real_data, fake_data):\n",
    "        real_data = real_data.view(mb_size, -1)\n",
    "        fake_data = fake_data.view(mb_size, -1)\n",
    "        real_data = real_data.view(real_data.size(0), -1)\n",
    "        fake_data = fake_data.view(fake_data.size(0), -1)\n",
    "        alpha = torch.rand(mb_size, 1).cuda()\n",
    "        alpha = alpha.expand(real_data.size())\n",
    "\n",
    "        interpolates = alpha * real_data + ((1 - alpha) * fake_data)\n",
    "\n",
    "        interpolates = Variable(interpolates, requires_grad=True).cuda()\n",
    "\n",
    "        interpolates = interpolates.view(mb_size, 1, 64, 64)\n",
    "        disc_interpolates = self(interpolates)\n",
    "\n",
    "        gradients = autograd.grad(outputs=disc_interpolates, inputs=interpolates,\n",
    "                                  grad_outputs=torch.ones(disc_interpolates.size()).cuda(),\n",
    "                                  create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "\n",
    "        gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * 1\n",
    "        return gradient_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = Generator()\n",
    "G.cuda()\n",
    "#G.weight_init()\n",
    "D = Discriminator()\n",
    "D.cuda()\n",
    "#D.weigth_init()\n",
    "\n",
    "G_solver = optim.Adamax(G.parameters(), lr=1e-4)\n",
    "D_solver = optim.SGD(D.parameters(), lr=1e-4)\n",
    "\n",
    "#loader = DataLoader(X_train, batch_size=64, drop_last=True)\n",
    "loader = DataLoader(mnist, mb_size, drop_last=True)\n",
    "\n",
    "one = torch.FloatTensor([1]).cuda()\n",
    "mone = one * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e41d8d28a2404222bbd1800cd08bdc30"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "782f797f59c2434ab60f9b66f5601ba3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5baa5e87aa3455bb321b196e4a2bc77"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6bcebacdd384e0d8d79750f1fded325"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1, 64, 64])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-129-9a3ee8bd8f20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;31m# train with gradient penalty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mgp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_pen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG_sample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mgp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mD_cost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD_fake\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mD_real\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \"\"\"\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 98\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "e_bar = tqdm_notebook(range(10000))\n",
    "D_losses = []\n",
    "G_losses = []\n",
    "for _ in e_bar:\n",
    "    D_loss_avg = 0\n",
    "    G_loss_avg = 0\n",
    "    \n",
    "    b_bar = tqdm_notebook(loader, leave=False)\n",
    "    \n",
    "    for X, _ in b_bar:\n",
    "        X = Variable(X).cuda()\n",
    "        for iter_d in range(1):\n",
    "            for p in D.parameters():\n",
    "                p.requires_grad = True  \n",
    "            D.zero_grad()\n",
    "            D_real = D(X)\n",
    "            D_real = D_real.mean()\n",
    "            # print D_real\n",
    "            D_real.backward(mone)\n",
    "\n",
    "            # train with fake\n",
    "            z = Variable(torch.randn(mb_size, z_dim), volatile=True).cuda()\n",
    "            z = z.view(-1, 100, 1, 1)\n",
    "            G_sample = Variable(G(z).data)\n",
    "            D_fake = D(G_sample)\n",
    "            D_fake = D_fake.mean()\n",
    "            D_fake.backward(one)\n",
    "\n",
    "            # train with gradient penalty\n",
    "            gp = D.grad_pen(X.data, G_sample.data)\n",
    "            gp.backward()\n",
    "\n",
    "            D_cost = D_fake - D_real + gp\n",
    "            Wasserstein_D = D_real - D_fake\n",
    "            D_solver.step()\n",
    "            \n",
    "            D_loss_avg += D_cost.data[0]\n",
    "            \n",
    "            b_bar.set_postfix(D_loss = F_cost)\n",
    "            \n",
    "            \n",
    "        for p in D.parameters():\n",
    "            p.requires_grad = False  # to avoid computation\n",
    "        G.zero_grad()\n",
    "\n",
    "        z = Variable(torch.randn(mb_size, z_dim)).cuda()\n",
    "        z = z.view(-1, 100, 1, 1)\n",
    "        G_sample = G(z)\n",
    "        G_loss = D(G_sample)\n",
    "        G_loss = G_loss.mean()\n",
    "        G_loss.backward(mone)\n",
    "        G_cost = -G_loss\n",
    "        G_solver.step()\n",
    "        \n",
    "        G_loss_avg += G_cost.data[0]\n",
    "        \n",
    "    D_losses.append(D_loss_avg / len(loader))\n",
    "    G_losses.append(G_loss_avg / len(loader))\n",
    "    \n",
    "    D_loss_avg = 0\n",
    "    G_loss_avg = 0\n",
    "    \n",
    "    e_bar.set_postfix(\n",
    "        D_loss = D_losses[-1],\n",
    "        G_loss = G_losses[-1]\n",
    "    )\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 64, 64)\n",
      "float32\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc45b614940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_imgs():\n",
    "    z = Variable(torch.randn(mb_size, z_dim)).cuda().view(-1, 100, 1, 1)\n",
    "    G_sample = G(z).data.cpu().numpy()\n",
    "    G_sample = G_sample.reshape(-1, 64, 64)[0:1]\n",
    "    print(G_sample.shape)\n",
    "    print(G_sample.dtype)\n",
    "    for x in G_sample:\n",
    "        plt.figure()\n",
    "        plt.imshow(x)\n",
    "    plt.show()\n",
    "    \n",
    "show_imgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
